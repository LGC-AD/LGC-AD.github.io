<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Salvaging the Overlooked: Leveraging Class-Aware Contrastive Learning for Multi-Class Anomaly Detection</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Salvaging the Overlooked: Leveraging Class-Aware Contrastive Learning for Multi-Class Anomaly Detection</h1>
            <div class="is-size-5 publication-authors">
              
             
              <!-- Paper authors -->
              
              
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://hellodfan.github.io/" target="_blank">Lei Fan</a><sup>1,2</sup><sup>*</sup>,</span>
                <span class="author-block">
                    Junjie Huang<sup>2</sup>,
                  <span class="author-block">
                    Donglin Di<sup>2</sup>,
                  </span>
                  <span class="author-block">
                    Anyang Su<sup>2</sup>,
                  <span class="author-block">
                    Tianyou Song<sup>3</sup>,
                  </span>
                  <span class="author-block">
                    Maurice Pagnucco</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://cgi.cse.unsw.edu.au/~ysong/" target="_blank">Yang Song</a></a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">ICCV 2025</span>
                    <span class="eql-cntrb"><small><br><sup>1</sup>CSE, UNSW Sydney,   </small><small><sup>2</sup>DZ-Matrix,  
                    </small> <small><sup>3</sup>Columbia University </small> 
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span>
                  </div>
                  <div class="column has-text-centered">
                    <div class="publication-links">
                      
                      <!-- Arxiv PDF link 
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                   
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>
                -->
                  <!-- Github link -->
                 

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2412.04769" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>


              <span class="link-block">
                <a href="https://github.com/LGC-AD/AD-LGC" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>


            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            For anomaly detection (AD), early approaches often train separate models for individual classes, yielding high performance
             but posing challenges in scalability and resource management. Recent efforts have shifted toward training a single model capable
              of handling multiple classes. However, directly extending early AD methods to multi-class settings often results in degraded performance.
          </p>
          <p>
             In this paper, we investigate this performance degradation observed in reconstruction-based methods, identifying the key issue:
              inter-class confusion. This confusion emerges when a model trained in multi-class scenarios incorrectly reconstructs samples from
               one class as another, thereby exacerbating reconstruction errors. To this end, we propose a simple yet effective modification, 
               called class-aware contrastive learning (CCL). By explicitly leveraging raw object category information (e.g., carpet or wood) as 
               supervised signals, we introduce local CL to refine multiscale dense features, and global CL to obtain more compact feature 
               representations of normal patterns, thereby effectively adapting the models to multi-class settings. Experiments across five datasets
                validate the effectiveness of our approach, demonstrating significant improvements and superior performance compared to state-of-the-art
                 methods. Notably, ablation studies indicate that pseudo-class labels can achieve comparable performance.
          </p>
          <p>                 
                 (This is version 2 of the paper, which includes additional experiments and analysis, compared to the first version (V1: Revitalizing Reconstruction Models for Multi-class Anomaly Detection via Class-Aware Contrastive Learning ).)
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<section class="section single-image-section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-half has-text-centered">
        <!-- 图片 -->
        <img src="static/images/lgc-confusion.png" alt="Image description" class="single-image">
        <!-- Caption -->
        <div class="content has-text-justified">
        <p class="caption">
          We focus on the question: <b>"Why do one-for-one models degrade when trained on multiple classes?"</b>. Specifically, previous AD methods, such as
          RD, DeSTSeg, SimpleNet, DRAEM, perform well yet training different models for different categories. We refer to such training strategy 
          one-for-one models, which is challenging to handle due to computational cost and model management. However, when directly trianing these
          one-for-one models on multiple classes, the performance will decrease significantly.
        </p>
        
        <p>We found two issues when training one-for-one models on multiple classes:</p>
        <ul>
          <li>
            <b>Catastrophic forgetting:</b> The model struggles to retain
            previously learned knowledge as new classes are introduced.
          </li>
          <li>
            <b>Inter-class confusion:</b> The models incorrectly reconstructed an input image of the 'carpet' class as 'wood' or misinterpreted 'transistor' as 'tile'. The model struggled to maintain accurate texture styles, particularly when anomalies exhibited stylistic similarities to other classes.
          </li>
        </ul>
        

      </div>
      </div>
    </div>
  </div>
</section>



<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/LGC-model.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <b> Overview of LGC</b>. Building on existing reconstruction-based models, we employ a projector layer following the encoder and apply 
          both local CL and global CL around the neck to capture more compact feature representations for each class. 
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/LGC-lcl.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <b> Contrastive Learning.</b> For spatial position (i, j) within an anchor feature v1, we compute its similarity with corresponding
features in an augmented feature v'1 and another sameclass sample v2, constrained to a window of size k x k. The features within this window are flattened, and the maximum similarity
value in the resulting similarity matrix is identified. The most similar pairs are treated as positive samples
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/LGC-visual.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <b>Visualization of different models across four datasets: MVTec, VISA, BTAD and Real-IAD under the all-in-all setting.</b>
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/LGC-performance.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        <b>Comparison of various one-for-all models across four datasets</b>. Domain-in-all refers to combining all classes within each
        dataset, while All-in-all signifies combining all classes across all datasets. Results are presented as I-AUROC / P-AUROC / PRO (%).
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        # we will update the BibTex citation once the camera-ready version is available
        @article{fan2024revitalizing,
          title={Revitalizing Reconstruction Models for Multi-class Anomaly Detection via Class-Aware Contrastive Learning},
          author={Fan, Lei and Huang, Junjie and Di, Donglin and Su, Anyang and Pagnucco, Maurice and Song, Yang},
          journal={arXiv preprint arXiv:2412.04769},
          year={2024}
        }


      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank"> 
              This website</a>, licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">CCA-S 4.0</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
